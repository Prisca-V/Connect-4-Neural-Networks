components:
- components:
  - layout_properties: {grid_position: 'ODUTHU,LBRXHP'}
    name: spacer_7
    properties: {height: 68}
    type: Spacer
  - components:
    - layout_properties: {grid_position: 'SMNRIB,ZFSSST'}
      name: headline_1
      properties: {role: game-title, text: Report}
      type: Label
    - event_bindings: {}
      layout_properties: {grid_position: 'SMNRIB,HITQSP'}
      name: Play_game
      properties: {align: right, icon_align: right, role: elevated-button, text: Play Game}
      type: Button
    - layout_properties: {grid_position: 'NUIDAF,LCBBTA'}
      name: spacer_1
      properties: {height: 32}
      type: Spacer
    layout_properties: {grid_position: 'RHYSQN,CUJXKE'}
    name: column_panel_3
    properties: {}
    type: ColumnPanel
  - layout_properties: {grid_position: 'UUJPKQ,FKAUYJ'}
    name: lbl_dataGen
    properties: {role: report-title, text: Data Generation}
    type: Label
  - components:
    - components: []
      layout_properties: {grid_position: 'OGNZIQ,BQHTUN'}
      name: data_den_text
      properties:
        background: theme:Light Overlay 1
        content: |
          The dataset is generated by having two agents play Connect Four against each other using Monte Carlo Tree Search (MCTS). To increase diversity, each game may begin with a few random opening moves. These random moves are not included in the dataset , only positions that result from MCTS decisions are stored.
        role: report-body
        spacing:
          padding: [null, null, null, 13]
      type: RichText
    - layout_properties: {grid_position: 'LPUCRU,LCOUGH'}
      name: rich_text_4
      properties:
        background: theme:Light Overlay 1
        content: After the opening phase, MCTS selects moves based on a configurable search depth that controls how strong the agent plays. At each valid turn, the current board is encoded from the perspective of the player to move using a 6×7×2 tensor. The first channel represents the current player’s discs, and the second channel represents the opponent’s discs. This canonical encoding removes the need for a separate turn indicator and allows a single model to learn both players’ strategies.
        role: report-body
        spacing:
          padding: [null, null, null, 13]
      type: RichText
    - data_bindings: []
      event_bindings: {}
      layout_properties: {grid_position: 'XQWEVP,VSTNRA'}
      name: rich_text_2
      properties:
        background: theme:Light Overlay 1
        content: |-
          To avoid storing duplicate positions, each board state is converted into a byte hash and used as a key in a lookup table. Instead of saving repeated boards multiple times, the system aggregates them. For each unique state, a 7-element count vector records how often MCTS selects each column. The final label can be assigned using a majority vote, and positions with low agreement can optionally be filtered out.
          The generator also supports horizontal symmetry augmentation by mirroring board states and corresponding column labels. Checkpoints are saved periodically so generation can resume if interrupted. After all games are completed, the aggregated states are converted into feature tensors and label arrays, resulting in a deduplicated and policy-consistent dataset suitable for supervised training.
        format: restricted_html
        role: report-body
        spacing:
          padding: [null, null, null, 13]
        tooltip: ''
      type: RichText
    layout_properties: {grid_position: 'IJPOSL,EMJLFU'}
    name: outlined_card_5
    properties: {background: '', role: report-card}
    type: ColumnPanel
  - components: []
    layout_properties: {grid_position: 'IBKSZC,NXMORG'}
    name: Data_Generation
    properties: {}
    type: LinearPanel
  - components:
    - name: lbl_mdl_bld
      properties: {role: report-title, text: Model Building}
      type: Label
    - components:
      - layout_properties: {grid_position: 'KPMLVQ,MVHTOR'}
        name: lbl_cnn
        properties: {bold: false, role: report-title, text: Convolutional Neural Network-CNN, underline: false}
        type: Label
      - layout_properties: {grid_position: 'IOMQTA,BSCAXG'}
        name: label_12
        properties: {role: report-subhead, text: Model Overview}
        type: Label
      - layout_properties: {grid_position: 'JUUJDD,PTYSIG'}
        name: cnn_text
        properties:
          content: '***'
          role: report-body
          spacing:
            padding: [null, 0, null, null]
        type: RichText
      - layout_properties: {grid_position: 'XCZUYX,GWRCUN'}
        name: label_13
        properties: {role: report-subhead, text: Model Architecture}
        type: Label
      - layout_properties: {grid_position: 'WYRBET,CIWOWJ'}
        name: caption_1
        properties: {role: caption, text: Input Representation}
        type: Label
      - layout_properties: {grid_position: 'XFFNIZ,SXMXLQ'}
        name: report_body_1
        properties: {role: report-body}
        type: RichText
      - layout_properties: {grid_position: 'DTEEYP,HSKXZI'}
        name: caption_2
        properties: {role: caption, text: Patch Strategy}
        type: Label
      - layout_properties: {grid_position: 'SVBBPF,DMMOXV'}
        name: report_body_2
        properties: {role: report-body}
        type: RichText
      - layout_properties: {grid_position: 'WDDVNI,ZHHDKC'}
        name: caption_3
        properties: {role: caption, text: Transformer Configuration}
        type: Label
      - layout_properties: {grid_position: 'ITJRFP,LVQYAR'}
        name: report_body_3
        properties: {role: report-body}
        type: RichText
      - layout_properties: {grid_position: 'XJRAKV,XFTBTF'}
        name: report_subhead_1
        properties: {role: report-subhead, text: Training Process}
        type: Label
      - layout_properties: {grid_position: 'LWYIDX,OGZVPT'}
        name: report_body_4
        properties: {role: report-body}
        type: RichText
      - layout_properties: {grid_position: 'LUXLXP,EDRRNZ'}
        name: report_subhead_2
        properties: {role: caption, text: What Worked Well}
        type: Label
      - layout_properties: {grid_position: 'TFFWEU,GTYTAS'}
        name: report_body_5
        properties: {role: report-body}
        type: RichText
      - layout_properties: {grid_position: 'EIBRIU,POMYEP'}
        name: label_14
        properties: {role: caption, text: What Worked Poorly}
        type: Label
      - layout_properties: {grid_position: 'SPMYTF,DRPJIR'}
        name: report_body_6
        properties: {role: report-body}
        type: RichText
      - layout_properties: {grid_position: 'JYOIFT,RUJUGR'}
        name: label_15
        properties: {role: report-subhead, text: Board Analysis}
        type: Label
      - layout_properties: {grid_position: 'WERNGA,BPHLTF'}
        name: report_body_7
        properties: {role: report-body}
        type: RichText
      - layout_properties: {grid_position: 'MNWUCX,FLMMEX'}
        name: image_7
        properties: {}
        type: Image
      - layout_properties: {grid_position: 'MNWUCX,HMBOOQ'}
        name: image_8
        properties: {}
        type: Image
      - layout_properties: {grid_position: 'HYHHKF,EELXLE'}
        name: report_body_8
        properties: {role: report-body}
        type: RichText
      - layout_properties: {grid_position: 'VCIJYC,GGFCVE'}
        name: image_3
        properties: {}
        type: Image
      - layout_properties: {grid_position: 'VCIJYC,BXFNOP'}
        name: image_2
        properties: {}
        type: Image
      - layout_properties: {grid_position: 'YNAIID,YYXDRU'}
        name: label_16
        properties: {role: report-subhead, text: Final Performance}
        type: Label
      - layout_properties: {grid_position: 'ZOBXSL,PMKLII'}
        name: rich_text_1
        properties: {content: Board Analysis, role: report-body}
        type: RichText
      name: column_panel_1
      properties: {role: report-card}
      type: ColumnPanel
    - name: spacer_3
      properties: {height: 32}
      type: Spacer
    - layout_properties: {}
      name: spacer_6
      properties: {height: 24.5}
      type: Spacer
    - components:
      - layout_properties: {grid_position: 'IORYYM,ADVEVP'}
        name: lbl_trans
        properties: {bold: false, role: report-title, text: Transformer Model, underline: false}
        type: Label
      - layout_properties: {grid_position: 'KBTTIG,AHHGUR'}
        name: label_3
        properties: {role: report-subhead, text: Model Overview}
        type: Label
      - components: []
        layout_properties: {grid_position: 'ARVPXR,TVKYUI'}
        name: trans_text
        properties:
          content: |
            For this project, I built a Vision Transformer (ViT) to learn Connect 4 strategy from Monte Carlo Tree Search (MCTS) data. The transformer treats the Connect 4 board as an image and uses self-attention mechanisms to identify winning patterns.Unlike CNNs that use fixed convolutional filters, transformers use attention mechanisms that can dynamically focus on any part of the board. This is particularly useful for Connect 4, where the importance of a position depends heavily on context. A piece in column 3 might be critical for blocking an opponent's diagonal, but irrelevant in another game state.
          format: restricted_html
          role: report-body
        type: RichText
      - layout_properties: {grid_position: 'BPRFHT,NDFGFZ'}
        name: label_5
        properties: {role: report-subhead, text: Model Architecture}
        type: Label
      - layout_properties: {grid_position: 'LNYCYQ,LYCYXU'}
        name: label_8
        properties: {role: caption, text: Input Representation}
        type: Label
      - layout_properties: {grid_position: 'MCOPVF,QFNHNC'}
        name: rich_text_6
        properties:
          content: |-
            <ul>
              <li><b>Board encoding:</b> 6×7×2</li>
              <li><b>Channel 0:</b> Player +1's pieces</li>
              <li><b>Channel 1:</b> Player -1's pieces</li>
              <li><b>Empty cells:</b> 0 in both channels</li>
              <li><b>Why two channels?</b> Helps the model distinguish players more clearly than a single-channel encoding.</li>
            </ul>
          format: restricted_html
          role: report-body
        type: RichText
      - layout_properties: {grid_position: 'HDGIPR,WCGZAH'}
        name: label_6
        properties: {role: caption, text: Patch Strategy}
        type: Label
      - layout_properties: {grid_position: 'OYCOPJ,ZYPULH'}
        name: rich_text_5
        properties:
          content: |-
            <ul>
              <li><b>Patch size:</b> 3×3 with stride 2 (overlapping patches)</li>
              <li><b>Total patches:</b> 9 (3 rows × 3 columns)</li>
              <li><b>Values per patch:</b> 3×3×2 = 18</li>
              <li><b>Why overlapping?</b> Overlapping patches capture 4-in-a-row patterns that span multiple regions of the board.</li>
            </ul>
          format: restricted_html
          role: report-body
        type: RichText
      - layout_properties: {grid_position: 'VYOLKM,TAGHEV'}
        name: label_7
        properties: {role: caption, text: Transformer Configuration}
        type: Label
      - layout_properties: {grid_position: 'AFFZWQ,JHZAGJ'}
        name: rich_text_7
        properties:
          content: |-
            <p><b>After experimentation, I settled on these hyperparameters:</b></p>

            <ul>
              <li><b>Hidden Dimension:</b> 64</li>
              <li><b>Transformer Layers:</b> 4</li>
              <li><b>Attention Heads:</b> 8 — allows the model to attend to horizontal, vertical, and diagonal patterns simultaneously</li>
              <li><b>MLP Dimension:</b> 128 (2× hidden dimension for feedforward network)</li>
              <li><b>Dropout:</b> 0.2 — regularization to prevent overfitting</li>
            </ul>
          format: restricted_html
          role: report-body
        type: RichText
      - layout_properties: {grid_position: 'OVUONC,OHEHIB'}
        name: label_4
        properties: {role: report-subhead, text: Training Process}
        type: Label
      - layout_properties: {grid_position: 'CMMHGY,ZQMJFB'}
        name: rich_text_8
        properties:
          content: |-
            <p><b>Dataset:</b></p>
            <ul>
              <li>MCTS-generated positions</li>
              <li>Total board positions: 131,980</li>
              <li>Training samples: 105,584 (80%)</li>
              <li>Validation samples: 26,396 (20%)</li>
              <li>Labels: Best move (column 0–6) determined by MCTS visit counts</li>
            </ul>

            <p>
            The dataset was loaded and preprocessed by decoding each board position from its binary representation into the 6×7×2 format. Each board was then converted into patches (9 patches of size 18, representing flattened 3×3×2 patches). The data was randomly shuffled and split into training and validation sets with an 80/20 split. Training proceeded in batches of 128, resulting in 825 training batches and 207 validation batches per epoch.
            </p>

            <p><b>Training Details:</b></p>
            <ul>
              <li>Framework: PyTorch (switched from TensorFlow for AWS deployment compatibility)</li>
              <li>Batch size: 128</li>
              <li>Optimizer: Adam with learning rate 0.0001</li>
              <li>Early stopping: Patience of 5 epochs monitoring validation loss</li>
            </ul>
          format: restricted_html
          role: report-body
        type: RichText
      - layout_properties: {grid_position: 'DYGEBF,DZIDCN'}
        name: label_9
        properties: {role: caption, text: What Worked Well}
        type: Label
      - layout_properties: {grid_position: 'OCKJFN,ZFYYNK'}
        name: rich_text_9
        properties:
          content: |-
            <p><b>Overlapping Patches</b></p>
            <p>
            The 3×3 patches with stride 2 proved effective. Because Connect 4 requires detecting 4-in-a-row patterns, overlapping patches helped the model see connections between adjacent board regions.
            </p>

            <p><b>Multiple Attention Heads</b></p>
            <p>
            Using 8 attention heads allowed the model to simultaneously look for horizontal threats (rows), vertical builds (columns), diagonal patterns, and blocking opportunities.
            </p>

            <p><b>Balanced Model Size</b></p>
            <p>
            Hidden dimension of 64 with 4 layers struck a good balance. It was large enough to capture complex patterns, but small enough to train quickly and avoid overfitting.
            </p>
          format: restricted_html
          role: report-body
        type: RichText
      - layout_properties: {grid_position: 'WRLHRU,HDIWFO'}
        name: label_10
        properties: {role: caption, text: What Worked Poorly}
        type: Label
      - layout_properties: {grid_position: 'GRKCJP,BAOFPS'}
        name: rich_text_10
        properties:
          content: |-
            <p><b>Initial TensorFlow Deployment Issues</b></p>
            <p>
            Spent significant time troubleshooting model serialization. TensorFlow 2.9.1 (required by Docker) couldn't load models saved in TF 2.18+. The .h5, .keras, and SavedModel formats all had version compatibility issues. Solution: Complete rewrite in PyTorch.
            </p>

            <p><b>Limited Strategic Depth</b></p>
            <p>
            The model learns pattern recognition, not strategic planning. It's excellent at tactical moves (blocking immediate threats, taking obvious wins) but struggles with setups requiring 2–3 move foresight. MCTS can think ahead many moves, but the transformer only sees one snapshot.
            </p>

            <p><b>Early-Game Uncertainty</b></p>
            <p>
            In opening positions with many valid moves, the model shows low confidence. Validation accuracy on early-game positions is around 35–40%, while late-game positions achieve 65–75%. This makes sense. Early moves are more “artistic” while late-game moves are more forced.
            </p>
          format: restricted_html
          role: report-body
        type: RichText
      - layout_properties: {grid_position: 'HWKKLF,VBVBFA'}
        name: label_1
        properties: {role: report-subhead, text: Board Analysis}
        type: Label
      - layout_properties: {grid_position: 'ZXYHYO,SNCOXY'}
        name: rich_text_11
        properties:
          content: |
            <p><b>Easy Boards</b></p>
            <p>
            The easiest board position for the transformer to predict is unsurprisingly when there is only one choice to make. In this case the model can’t make the wrong choice because there’s only one move to make.
            </p>
          format: restricted_html
          role: report-body
        type: RichText
      - layout_properties: {grid_position: 'YXTRYU,XYKEGZ'}
        name: image_1
        properties: {source: _/theme/Screenshot 2026-02-15 174804.png}
        type: Image
      - layout_properties: {grid_position: 'YXTRYU,MVVAXD'}
        name: image_4
        properties: {source: _/theme/Screenshot 2026-02-15 174850.png}
        type: Image
      - components: []
        layout_properties: {grid_position: 'SDOFYV,YSUWQU'}
        name: rich_text_3
        properties:
          content: |-
            <p><b>Difficult Boards</b></p>
            <p>
            Taking a look at the boards that were the most difficult for the model to predict, we clearly see that it’s when there are many options. If there is no clear win, it’s difficult for the model to predict what the most advantageous move is.
            </p>
          format: restricted_html
          role: report-body
        type: RichText
      - layout_properties: {grid_position: 'SFPGLD,EWVMEP'}
        name: image_5
        properties: {source: _/theme/Screenshot 2026-02-15 175951.png}
        type: Image
      - layout_properties: {grid_position: 'SFPGLD,FKAPBT'}
        name: image_6
        properties: {source: _/theme/Screenshot 2026-02-15 180051.png}
        type: Image
      - layout_properties: {grid_position: 'KJVSTU,HKEXUD'}
        name: label_11
        properties: {role: report-subhead, text: Final Performance}
        type: Label
      - layout_properties: {grid_position: 'RVSBYK,UPPRVX'}
        name: rich_text_12
        properties:
          content: |-
            <p><b>Training Results:</b></p>

            <ul>
              <li>Training Loss: 1.1954</li>
              <li>Training Accuracy: 52.35%</li>
              <li>Validation Loss: 1.2312</li>
              <li>Validation Accuracy: 51.40%</li>
            </ul>

            <div style="height:10px;"></div>

            <p>
            This accuracy is quite good considering the task complexity. With 7 possible moves, random guessing would achieve only 14% accuracy. The model achieves <b>3.6× better than random</b>, demonstrating it has learned meaningful Connect 4 strategy from the MCTS data.
            </p>

            <p>
            The validation accuracy of 51% means the model predicts the exact same move as MCTS more than half the time. Many positions have multiple reasonable moves with similar strategic value, so cases where the model chooses a different (but still good) move are counted as “incorrect” even though they might be perfectly valid plays.
            </p>

            <p>
            The close alignment between training (52.35%) and validation (51.40%) accuracy suggests the model generalizes well without significant overfitting, which validates our choice of dropout (0.2) and model size.
            </p>
          format: restricted_html
          role: report-body
        type: RichText
      layout_properties: {}
      name: column_panel_2
      properties: {role: report-card}
      type: ColumnPanel
    - name: spacer_2
      properties: {height: 32}
      type: Spacer
    layout_properties: {grid_position: 'QSTSNQ,QPROWN'}
    name: Model_Building
    properties: {}
    type: LinearPanel
  layout_properties: {slot: default}
  name: home
  properties: {background: '#1a1a2e', col_widths: '{}', role: page}
  type: ColumnPanel
container:
  properties: {html: '@theme:standard-page.html'}
  type: HtmlTemplate
is_package: true
